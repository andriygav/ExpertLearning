\documentclass[12pt, twoside]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage{amsthm}
\usepackage{a4wide}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{euscript}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{caption}
\usepackage{color}
\usepackage{bm}
\usepackage{tabularx}
\usepackage{adjustbox}


\usepackage[toc,page]{appendix}

\usepackage{comment}
\usepackage{rotating}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\newtheorem{theorem}{Теорема}
\newtheorem{lemma}[theorem]{Лемма}
\newtheorem{definition}{Определение}[section]

\numberwithin{equation}{section}

\newcommand*{\No}{No.}
\begin{document}

\title{\bf Задание априорных ограничений на все сразу}
\date{}
\author{}
\maketitle

\section{Честная Gate Function}
\[
\label{eq:em:2}
\begin{aligned}
\log p\bigr(\mathbf{y}, \mathbf{Z}, \mathbf{W}&|\mathbf{X}, \mathbf{V}, \textbf{A}, \textbf{W}^{0},  \bm{\Xi}, \beta, \bm{\mu}\bigr) =\\
&= {\color{red}\sum_{i=1}^{N}\sum_{k=1}^{K}z_{ik}\left[\log\pi_k\bigr(\textbf{x}_i, \textbf{V}\bigr) - \frac{\beta}{2}\left(y_{i} - \textbf{w}_{k}^{\mathsf{T}}\textbf{x}_{i}\right)^{2} + \frac{1}{2}\log\frac{\beta}{2\pi}\right]} +\\
&+ {\color{blue}\sum_{k=1}^{K}\left[-\frac{1}{2}\left(\textbf{w}_{k} - \textbf{w}_{k}^{0}\right)^{\mathsf{T}}\textbf{A}_{k}^{-1}\left(\textbf{w}_{k} - \textbf{w}_{k}^{0}\right) + \frac{1}{2}\log\det\textbf{A}^{-1}_{k} - \frac{n}{2}\log2\pi\right]}+\\
&+{\color{cyan}R\bigr(\textbf{W}^0\bigr)} + {\color{magenta}\sum_{i=1}^{N}\sum_{k=1}^{K}\mu_k\log\pi_k\bigr(\textbf{x}_i, \textbf{V}\bigr)}.
\end{aligned}
\]

\begin{enumerate}
	\item {\color{red}red}: правдоподобие выборки;
	\item {\color{blue}blue}: априорное распределение на параметры модели (говорим что параметры на самом деле из нормального распределения с параметрами $w_k^0$, $A_k$);
	\item {\color{cyan}cyan}: ограничения на prior параметров модели (говорим что априорное распределение  какое-то хорошее: например сумма всех $w_k^0$ должна равняться нулю);
	\item {\color{magenta}magenta}: ограничения на gate function. Конкретно в этом примере говорим, что ответы нейросети в априори должны иметь распределение Дирихле (посути вводим ограничение, что все модели не зависимо от объекта имеют некоторую вероятность);
\end{enumerate}

\section{Sparse Gate Function}
Большой минус в работе Gate Function это то что там нету аналитической формулы для решения, поэтому приходится использовать градиентные методы которые не всегда сходятся с глобальному минимуму (это еще поверх того, что сам EM алгоритм тоже не всегда сходится к глобальному минимум, вот на этом всем у нас плохое качество получается)

\textit{Замечание}. Gate function это некоторая функция, которая нужна нам только в некоторых точках. Давайте вместо востановления всей функции рассмотрим только матрицу: значение Gate Function в данных точках. Обозначим данную матрицу:
\[
\begin{aligned}
\hat{\bm{\pi}} = \bigr[\pi_k^i\bigr]_{k=1, i=1}^{K, N},
\end{aligned}
\]
назовем~$\hat{\bm{\pi}}$ как \textit{Sparse Gate Function}.

В этом случае запишем функцию правдоподобие:
\[
\label{eq:em:2}
\begin{aligned}
\log p\bigr(\mathbf{y}, \mathbf{Z}, \mathbf{W}&|\mathbf{X}, \textbf{A}, \textbf{W}^{0},  \bm{\Xi}, \beta, \bm{\mu}\bigr) =\\
&= {\color{red}\sum_{i=1}^{N}\sum_{k=1}^{K}z_{ik}\left[\log\pi_k^i - \frac{\beta}{2}\left(y_{i} - \textbf{w}_{k}^{\mathsf{T}}\textbf{x}_{i}\right)^{2} + \frac{1}{2}\log\frac{\beta}{2\pi}\right]} +\\
&+ {\color{blue}\sum_{k=1}^{K}\left[-\frac{1}{2}\left(\textbf{w}_{k} - \textbf{w}_{k}^{0}\right)^{\mathsf{T}}\textbf{A}_{k}^{-1}\left(\textbf{w}_{k} - \textbf{w}_{k}^{0}\right) + \frac{1}{2}\log\det\textbf{A}^{-1}_{k} - \frac{n}{2}\log2\pi\right]}+\\
&+  \sum_{i=1}^{N}\log\text{Dir}\bigr(\bm{\pi}^i|\bm{\mu}, \gamma\bigr) 
\end{aligned}
\]


\end{document}

